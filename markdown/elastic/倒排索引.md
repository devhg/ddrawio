**每种数据库都有自己要解决的问题（或者说擅长的领域），对应的就有自己的数据结构，而不同的使用场景和数据结构，需要用不同的索引，才能起到最大化加快查询的目的。**

对于 MySQL 来说，使用 B+ tree 索引是为了写入的索引存储结构。对于不需要快速更新的时候，采用预先排序等方式换取更小的存储空间，更快的检索速度，但同时，由于每次更新都需要对 B+ 树进行调整，导致更新比较慢。Elasticsearch 是通过 Lucene 的倒排索引技术实现比关系型数据库更快的过滤。特别是它对多条件的过滤支持非常好。

> Elasticsearch 是建立在全文搜索引擎库 Lucene 基础上的搜索引擎，它隐藏了 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API，不过掩盖不了它底层也是 Lucene 的事实。
> Elasticsearch 的倒排索引，其实就是 Lucene 的倒排索引。



# 1. 什么是倒排索引

倒排：关键词到页号或文章id

正排：类似一本书的目录。

先倒排后正排：在目录上记关键词，通过关键词找到目录章节页号，通过页号找到内容。

# 2. 倒排索引的内部结构

首先，在数据生成的时候，比如插入一份文档，内容是“生存还是死亡”，这个时候通过使用分词器，会将它分解为“生存”、“还是”、“死亡”三个词语，然后可能还会把“还是”这个无意义的词语干掉。

接着，就会将这两个词语以及对应的文档 id 存下来：

| Term | Posting list |
| ---- | ------------ |
| 生存 | [1]          |
| 死亡 | [1]          |

然后我们再插入一个文档，这个内容是“生存”，于是索引就变成了：

| Term | Posting list |
| ---- | ------------ |
| 生存 | [1,2]        |
| 死亡 | [1]          |

下回在搜索“生存”的时候，就会返回1，2两份文档。

![](elastic.assets/01.jpg)

可以看到，倒排索引是per field的，一个字段由一个自己的倒排索引。`生存,存亡`这些叫做 term，而[1,2]就是posting list。Posting list就是一个int的数组，存储了所有符合某个term的文档id。那么什么是term dictionary 和 term index？

假设我们有很多个term，比如：

Carla,Sara,Elin,Ada,Patty,Kate,Selena

如果按照这样的顺序排列，找出某个特定的term一定很慢，因为term没有排序，需要全部过滤一遍才能找出特定的term。排序之后就变成了：

Ada,Carla,Elin,Kate,Patty,Sara,Selena

这样我们可以用二分查找的方式，比全遍历更快地找出目标的term。这个就是 term dictionary。有了term dictionary之后，可以用 logN 次磁盘查找得到目标。但是磁盘的随机读操作仍然是非常昂贵的（一次random access大概需要10ms的时间）。所以尽量少的读磁盘，有必要把一些数据缓存到内存里。但是整个term dictionary本身又太大了，无法完整地放到内存里。于是就有了term index。term index有点像一本字典的大的章节表。比如：

A开头的term ……………. Xxx页

C开头的term ……………. Xxx页

E开头的term ……………. Xxx页

如果所有的term都是英文字符的话，可能这个term index就真的是26个英文字符表构成的了。但是实际的情况是，term未必都是英文字符，term可以是任意的byte数组。而且26个英文字符也未必是每一个字符都有均等的term，比如x字符开头的term可能一个都没有，而s开头的term又特别多。实际的term index是一棵trie 树：

![img](elastic.assets/02.jpg)



例子是一个包含 "A", "to", "tea", "ted", "ten", "i", "in", 和 "inn" 的 trie 树。这棵树不会包含所有的term，它包含的是term的一些前缀。通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。再加上一些压缩技术（Lucene 的Finite State Transducers） term index 的尺寸可以只有所有term的尺寸的几十分之一，使得用内存缓存整个term index变成可能。整体上来说就是这样的效果。

**先倒排后正排。term dictionary --> posting list 倒排。term index --> term dictonary 正排**

![Lucene倒排索引内部结构](elastic.assets/Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84.jpg)

现在我们可以回答 “为什么Elasticsearch/Lucene检索可以比mysql快了”。

Mysql只有term dictionary这一层，是以b-tree排序的方式存储在磁盘上的。检索一个term需要若干次的random access的磁盘操作。而Lucene在term dictionary的基础上添加了term index来加速检索，term index以树的形式缓存在内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘的random access次数。

额外值得一提的两点是：term index在内存中是以**FST**（finite state transducers）的形式保存的，其特点是非常节省内存。Term dictionary在磁盘上是以分block的方式保存的，一个block内部利用公共前缀压缩，比如都是Ab开头的单词就可以把Ab省去。这样term dictionary可以比b-tree更节约磁盘空间。



# 3. 对 Posting List 的改进

原生的 Posting List 有两个可以改进的地方：

- 如何压缩以节省磁盘空间
- 如何快速求并交集

## 3.1 压缩

假设有这样一个数组：

```
[73, 300, 302, 332, 343, 372]
```

如何进行压缩呢？

在Lucene里，数据是按照 Segment 存储的，每个 Segment 最多存 65536 个文档 ID， 所以文档 ID 的范围，从 0 到 2^16-1，所以如果不进行任何处理，那么每个元素都会占用 2 bytes ，对应上面的数组，就是 6 * 2 = 12 bytes。

**压缩，就是尽可能降低每个数据占用的空间，同时又能让信息不失真，能够还原回来。**

### 增量编码

数据只记录元素与元素之间的增量，于是数组变成了：

```
[73, 227, 2, 30, 11, 29]
```

### 分割成块

Lucene 里每个块是 256 个文档 ID，这样可以保证每个块，增量编码后，每个元素都不会超过 256（1 byte），另外还方便进行后面求交并集的跳表运算。

为了方便演示，我们假设每个块是 3 个文档 ID：

```
[73, 227, 2], [30, 11, 29]
```

### 按需分配空间

对于第一个块，[73, 227, 2]，最大元素是227，需要 8 bits，所以就给每个元素都分配 8 bits的空间。

但是对于第二个块，[30, 11, 29]，最大的元素才30，只需要 5 bits，所有给每个元素只分配 5 bits 的空间足矣。

以上三个步骤，共同组成了一项编码技术，Frame Of Reference（FOR）：

[![es FOR编码技术](elastic.assets/es%20FOR%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF.jpg)



## 3.2 快速求交并集

在 Lucene 中查询，通常不只有一个查询条件，比如想搜索：

- 含有“生存”相关词语的文档
- 文档发布时间在最近一个月
- 文档发布者是平台的特约作者

这样就需要根据三个字段，去三棵倒排索引里去查，当然，磁盘里的数据，上一节提到过，用了 FOR 进行压缩，所以我们要把数据进行反向处理，即解压，才能还原成原始的文档 ID，然后把这三个文档 ID 数组在内存中做一个交集。

> 即使没有多条件查询， Lucene 也需要频繁求并集，因为 Lucene 是分片存储的。

可以把 Lucene 遇到的问题，简化成一道算法题。

假设有下面三个数组：求它们的交集。

```
[64, 300, 303, 343]

[73, 300, 302, 303, 343, 372]

[303, 311, 333, 343]
```

### Integer 数组

直接用原始的文档 ID ，如果逐个数组遍历一遍，这样就可以求了，这样不管是空间还是性能都不够理想。

其实对于有序的数组，用跳表（skip table）可以更高效，但是不管是从性能，还是空间上考虑，Integer 数组都不靠谱，假设有100M 个文档 ID，每个文档 ID 占 2 bytes，那已经是 200 MB，而这些数据是要放到内存中进行处理的，把这么大量的数据，从磁盘解压后丢到内存，内存肯定撑不住。

### Bitmap

假设有这样一个数组：

```
[3,6,7,10]
```

那么可以这样通过使用 bitmap （位图）来表示：

```
[0,0,1,0,0,1,1,0,0,1]
```

**我们用 0 表示角标对应的数字不存在，用 1 表示存在。**

这样带来了两个好处：

- 节省空间：只需要 0 和 1，那每个文档 ID 就只需要 1 bit，还是假设有 100M 个文档，那只需要 100M bits = 100M / 8 Bytes = 12.5 MB，比之前用 Integer 数组的 200 MB 节省了大量的内存。
- 运算更快：0 和 1，天然就适合进行位运算，求交集，「与」一下，求并集，「或」一下，一切都回归到计算机的起点

### Roaring Bitmaps

bitmap 有个硬伤，就是不管你有多少个文档，你占用的空间都是一样的，之前说过，Lucene Posting List 的每个 Segement 最多放 65536 个文档ID，举一个极端的例子，有一个数组，里面只有两个文档 ID：

```
[0, 65535]
```

如果使用 bitmap 表示，那就需要：

```
[1,0,0,0,….(超级多个0),…,0,0,1]
```

需要 65536 个 bit，也就是 65536/8 = 8192 bytes，而用 Integer 数组，只需要 2 * 2 bytes = 4 bytes

可见在文档数量不多的时候，使用 Integer 数组更加节省内存。

计算一下临界值，很简单，无论文档数量多少，bitmap 都需要 8192 bytes，而 Integer 数组则和文档数量成线性相关，每个文档 ID 占 2 bytes，所以：8192 / 2 = 4096

当文档数量少于 4096 时，用 Integer 数组，否则，用 bitmap。

### 使用 Skip List（跳表）做合并计算

对于需要查找的每一个 int 数组建立跳表，然后由最短的 posting list 开始遍历，遍历的过程中各自可以跳过不少元素，比如下面的例子：

![Lucene跳表计算例子](elastic.assets/Lucene%E8%B7%B3%E8%A1%A8%E8%AE%A1%E7%AE%97%E4%BE%8B%E5%AD%90.jpg)

以上是三个posting list。现在需要把它们用AND的关系合并，得出posting list的交集。首先选择最短的posting list，然后从小到大遍历。遍历的过程可以跳过一些元素，比如我们遍历到绿色的13的时候，就可以跳过蓝色的3了，因为3比13要小。

整个过程如下：

```
Next -> 2
Advance(2) -> 13
Advance(13) -> 13
Already on 13
Advance(13) -> 13 MATCH!!!
Next -> 17
Advance(17) -> 22
Advance(22) -> 98
Advance(98) -> 98
Advance(98) -> 98 MATCH!!!
Copy
```



# 4. Roaring bitmaps 和 Frame Of Reference 的关系

`Frame Of Reference` 是压缩数据，减少磁盘占用空间，所以当我们从磁盘取数据时，也需要一个反向的过程，即解压，解压后才有我们上面看到的这样子的文档ID数组：[73, 300, 302, 303, 343, 372] ，接着我们需要对数据进行处理，求交集或者并集，这时候数据是需要放到内存进行处理的，我们有三个这样的数组，这些数组可能很大，而内存空间比磁盘还宝贵，于是需要更强有力的压缩算法，同时还要有利于快速的求交并集，于是有了Roaring Bitmaps 算法。

另外，Lucene 还会把从磁盘取出来的数据，通过 Roaring bitmaps 处理后，缓存到内存中，Lucene 称之为 filter cache.

# 5. 为什么 Elasticsearch/Lucene 检索可以比 mysql 快

Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次随机 IO 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了term index来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access （随机IO）次数。

**参考文档**

> [聊聊 Elasticsearch 的倒排索引](https://zhuanlan.zhihu.com/p/76485252)
>
> [elasticsearch 倒排索引原理](https://zhuanlan.zhihu.com/p/33671444)
>
> [Elasticsearch 倒排索引原理](https://xiaoming.net.cn/2020/11/25/Elasticsearch%20%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/)